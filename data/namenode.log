2016-11-14 18:53:59,134 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG:
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = ubuntu/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 1.2.1
STARTUP_MSG:   build = https://svn.apache.org/repos/asf/hadoop/common/branches/branch-1.2 -r 1503152; compiled by 'mattf' on Mon Jul 22 15:23:09 PDT 2013
STARTUP_MSG:   java = 1.8.0_60
************************************************************/
2016-11-14 18:53:59,310 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2016-11-14 18:53:59,323 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source MetricsSystem,sub=Stats registered.
2016-11-14 18:53:59,324 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2016-11-14 18:53:59,324 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2016-11-14 18:53:59,491 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source ugi registered.
2016-11-14 18:53:59,495 WARN org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Source name ugi already exists!
2016-11-14 18:53:59,503 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source jvm registered.
2016-11-14 18:53:59,505 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source NameNode registered.
2016-11-14 18:53:59,542 INFO org.apache.hadoop.hdfs.util.GSet: Computing capacity for map BlocksMap
2016-11-14 18:53:59,542 INFO org.apache.hadoop.hdfs.util.GSet: VM type       = 64-bit
2016-11-14 18:53:59,542 INFO org.apache.hadoop.hdfs.util.GSet: 2.0% max memory = 932184064
2016-11-14 18:53:59,542 INFO org.apache.hadoop.hdfs.util.GSet: capacity      = 2^21 = 2097152 entries
2016-11-14 18:53:59,542 INFO org.apache.hadoop.hdfs.util.GSet: recommended=2097152, actual=2097152
2016-11-14 18:53:59,586 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner=hadoop
2016-11-14 18:53:59,586 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup=supergroup
2016-11-14 18:53:59,586 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled=true
2016-11-14 18:53:59,597 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.block.invalidate.limit=100
2016-11-14 18:53:59,597 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s
)
2016-11-14 18:53:59,989 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemStateMBean and NameNodeMXBean
2016-11-14 18:54:00,017 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: dfs.namenode.edits.toleration.length = 0
2016-11-14 18:54:00,017 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2016-11-14 18:54:00,028 INFO org.apache.hadoop.hdfs.server.common.Storage: Start loading image file /opt/hadoop/hadoopData/name/current/fsimage
2016-11-14 18:54:00,028 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files = 1
2016-11-14 18:54:00,033 INFO org.apache.hadoop.hdfs.server.common.Storage: Number of files under construction = 0
2016-11-14 18:54:00,033 INFO org.apache.hadoop.hdfs.server.common.Storage: Image file /opt/hadoop/hadoopData/name/current/fsimage of size 112 bytes loaded in 0 seconds.
2016-11-14 18:54:00,033 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Start loading edits file /opt/hadoop/hadoopData/name/current/edits
2016-11-14 18:54:00,034 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: EOF of /opt/hadoop/hadoopData/name/current/edits, reached end of edit log Number of transac
tions found: 0.  Bytes read: 4
2016-11-14 18:54:00,034 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Start checking end of edit log (/opt/hadoop/hadoopData/name/current/edits) ...
2016-11-14 18:54:00,034 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Checked the bytes after the end of edit log (/opt/hadoop/hadoopData/name/current/edits):
2016-11-14 18:54:00,034 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog:   Padding position  = -1 (-1 means padding not found)
2016-11-14 18:54:00,034 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog:   Edit log length   = 4
2016-11-14 18:54:00,034 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog:   Read length       = 4
2016-11-14 18:54:00,034 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog:   Corruption length = 0
2016-11-14 18:54:00,034 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog:   Toleration length = 0 (= dfs.namenode.edits.toleration.length)
2016-11-14 18:54:00,037 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Summary: |---------- Read=4 ----------|-- Corrupt=0 --|-- Pad=0 --|
2016-11-14 18:54:00,037 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Edits file /opt/hadoop/hadoopData/name/current/edits of size 4 edits # 0 loaded in 0 second
s.
2016-11-14 18:54:00,038 INFO org.apache.hadoop.hdfs.server.common.Storage: Image file /opt/hadoop/hadoopData/name/current/fsimage of size 112 bytes saved in 0 seconds.
2016-11-14 18:54:00,261 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: closing edit log: position=4, editlog=/opt/hadoop/hadoopData/name/current/edits
2016-11-14 18:54:00,262 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: close success: truncate to 4, editlog=/opt/hadoop/hadoopData/name/current/edits
2016-11-14 18:54:00,530 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2016-11-14 18:54:00,530 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 961 msecs
2016-11-14 18:54:00,531 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.safemode.threshold.pct          = 0.9990000128746033
2016-11-14 18:54:00,532 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2016-11-14 18:54:00,532 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.safemode.extension              = 30000
2016-11-14 18:54:00,532 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of blocks excluded by safe block count: 0 total blocks: 0 and thus the safe block
s: 0
2016-11-14 18:54:00,553 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Total number of blocks = 0
2016-11-14 18:54:00,553 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of invalid blocks = 0
2016-11-14 18:54:00,553 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of under-replicated blocks = 0
2016-11-14 18:54:00,553 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of  over-replicated blocks = 0
2016-11-14 18:54:00,553 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode termination scan for invalid, over- and under-replicated blocks completed in 21 msec
2016-11-14 18:54:00,553 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 0 secs
2016-11-14 18:54:00,554 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 0 racks and 0 datanodes
2016-11-14 18:54:00,554 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
2016-11-14 18:54:00,568 INFO org.apache.hadoop.util.HostsFileReader: Refreshing hosts (include/exclude) list
2016-11-14 18:54:00,571 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: ReplicateQueue QueueProcessingStatistics: First cycle completed 0 blocks in 1 msec
2016-11-14 18:54:00,571 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: ReplicateQueue QueueProcessingStatistics: Queue flush completed 0 blocks in 1 msec proce
ssing time, 1 msec clock time, 1 cycles
2016-11-14 18:54:00,572 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: InvalidateQueue QueueProcessingStatistics: First cycle completed 0 blocks in 0 msec
2016-11-14 18:54:00,572 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: InvalidateQueue QueueProcessingStatistics: Queue flush completed 0 blocks in 0 msec proc
essing time, 0 msec clock time, 1 cycles
2016-11-14 18:54:00,581 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source FSNamesystemMetrics registered.
2016-11-14 18:54:00,604 INFO org.apache.hadoop.ipc.Server: Starting SocketReader
2016-11-14 18:54:00,608 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source RpcDetailedActivityForPort8020 registered.
2016-11-14 18:54:00,609 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source RpcActivityForPort8020 registered.
2016-11-14 18:54:00,612 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Namenode up at: localhost/127.0.0.1:8020
2016-11-14 18:54:00,705 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2016-11-14 18:54:00,815 INFO org.apache.hadoop.http.HttpServer: Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2016-11-14 18:54:00,832 INFO org.apache.hadoop.http.HttpServer: dfs.webhdfs.enabled = false
2016-11-14 18:54:00,839 INFO org.apache.hadoop.http.HttpServer: Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on
50070
2016-11-14 18:54:00,841 INFO org.apache.hadoop.http.HttpServer: listener.getLocalPort() returned 50070 webServer.getConnectors()[0].getLocalPort() returned 50070
2016-11-14 18:54:00,841 INFO org.apache.hadoop.http.HttpServer: Jetty bound to port 50070
2016-11-14 18:54:00,841 INFO org.mortbay.log: jetty-6.1.26
2016-11-14 18:54:00,974 WARN org.mortbay.log: Can't reuse /tmp/Jetty_0_0_0_0_50070_hdfs____w2cu08, using /tmp/Jetty_0_0_0_0_50070_hdfs____w2cu08_5922073993848817084
2016-11-14 18:54:01,696 INFO org.mortbay.log: Started SelectChannelConnector@0.0.0.0:50070
2016-11-14 18:54:01,696 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Web-server up at: 0.0.0.0:50070
2016-11-14 18:54:01,699 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2016-11-14 18:54:01,700 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8020: starting
2016-11-14 18:54:01,701 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 8020: starting
2016-11-14 18:54:01,701 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 8020: starting
2016-11-14 18:54:01,702 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 8020: starting
2016-11-14 18:54:01,702 INFO org.apache.hadoop.ipc.Server: IPC Server handler 3 on 8020: starting
2016-11-14 18:54:01,702 INFO org.apache.hadoop.ipc.Server: IPC Server handler 4 on 8020: starting
2016-11-14 18:54:01,703 INFO org.apache.hadoop.ipc.Server: IPC Server handler 5 on 8020: starting
2016-11-14 18:54:01,703 INFO org.apache.hadoop.ipc.Server: IPC Server handler 6 on 8020: starting
2016-11-14 18:54:01,704 INFO org.apache.hadoop.ipc.Server: IPC Server handler 7 on 8020: starting
2016-11-14 18:54:01,704 INFO org.apache.hadoop.ipc.Server: IPC Server handler 8 on 8020: starting
2016-11-14 18:54:01,705 INFO org.apache.hadoop.ipc.Server: IPC Server handler 9 on 8020: starting
2016-11-14 18:54:03,943 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: node registration from 127.0.0.1:50010 storage DS-1084848946-127.0.1.1-50010-147
9128943929
2016-11-14 18:54:03,949 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/127.0.0.1:50010
2016-11-14 18:54:04,009 INFO org.apache.hadoop.hdfs.StateChange: *BLOCK* NameNode.blocksBeingWrittenReport: from 127.0.0.1:50010 0 blocks
2016-11-14 18:54:04,030 INFO org.apache.hadoop.hdfs.StateChange: *BLOCK* processReport: from 127.0.0.1:50010, blocks: 0, processing time: 2 msecs
2016-11-14 18:54:07,111 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-hadoop/mapred/system/jobtracker.info. blk_-7819817684913559027_1001
2016-11-14 18:54:07,339 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_-7819817684913559027_1001 size 4
2016-11-14 18:54:07,341 INFO org.apache.hadoop.hdfs.StateChange: Removing lease on  /tmp/hadoop-hadoop/mapred/system/jobtracker.info from client DFSClient_NONMAPREDUCE_-1
459398303_1
2016-11-14 18:54:07,343 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-hadoop/mapred/system/jobtracker.info is closed by DFSClient_NONMAPREDUCE_-
1459398303_1
2016-11-14 18:59:04,513 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 127.0.0.1
2016-11-14 18:59:04,513 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 10 Total time for transactions(ms): 2 Number of transactions batche
d in Syncs: 0 Number of syncs: 5 SyncTimes(ms): 288
2016-11-14 18:59:04,513 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: closing edit log: position=874, editlog=/opt/hadoop/hadoopData/name/current/edits
2016-11-14 18:59:04,514 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: close success: truncate to 874, editlog=/opt/hadoop/hadoopData/name/current/edits
2016-11-14 18:59:05,826 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://0.0.0.0:50090/getimage?getimage=1
2016-11-14 18:59:05,930 INFO org.apache.hadoop.hdfs.server.namenode.GetImageServlet: Downloaded new fsimage with checksum: 91aea299ea469a8f0667f08b65559cef
2016-11-14 18:59:05,931 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll FSImage from 127.0.0.1
2016-11-14 18:59:05,932 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 0 Total time for transactions(ms): 0 Number of transactions batched
 in Syncs: 0 Number of syncs: 1 SyncTimes(ms): 89
2016-11-14 18:59:05,932 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: closing edit log: position=4, editlog=/opt/hadoop/hadoopData/name/current/edits.new
2016-11-14 18:59:05,932 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: close success: truncate to 4, editlog=/opt/hadoop/hadoopData/name/current/edits.new